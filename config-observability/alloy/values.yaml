alloy:
  controller:
    # -- Type of controller to use for deploying Grafana Alloy in the cluster.
    # Must be one of 'daemonset', 'deployment', or 'statefulset'.
    type: 'statefulset'
    rbac:
      create: true # This allows Alloy to read ServiceMonitors
  alloy:
    clustering:
      enabled: false
    configMap:
      content: |-
        logging {
          level  = "info"
          format = "logfmt"
        }

        // Enable livedebugging for troubleshooting
        livedebugging {
          enabled = true
        }
        
        // Add ruler integration
        mimir.rules.kubernetes "local" {
          address = "http://mimir-ruler.observability.svc.cluster.local:8080"
          tenant_id = "CompanyA-Cluster1-Jakarta"
        }

        // 1. Discover and scrape all ServiceMonitors (Node Exporter, KSM, etc.)
        prometheus.operator.servicemonitors "kube_stack" {
          forward_to = [prometheus.remote_write.mimir.receiver]
        }

        // 2. Discover and scrape all PodMonitors (if you have any)
        prometheus.operator.podmonitors "kube_stack" {
          forward_to = [prometheus.remote_write.mimir.receiver]
        }

        // 3. Discover mimir metrics endpoint for self-monitoring
        // 1. Discover all services in the cluster
        discovery.kubernetes "mimir_services" {
          role = "service"
        }

        // 2. Filter for specific Mimir components (e.g., those with a specific label)
        discovery.relabel "mimir_targets" {
          targets = discovery.kubernetes.mimir_services.targets

          // Keep only services with the label app=mimir or similar
          rule {
            source_labels = ["__meta_kubernetes_service_label_app"]
            regex         = "mimir.*"
            action        = "keep"
          }

          // Map the service name to a 'job' label for easier querying in Mimir
          rule {
            source_labels = ["__meta_kubernetes_service_name"]
            target_label  = "job"
          }
        }

        // 3. Scrape the discovered targets
        prometheus.scrape "mimir_metrics" {
          targets    = discovery.relabel.mimir_targets.output
          forward_to = [prometheus.remote_write.mimir.receiver]
        }

        // 3. Define the Remote Write destination (Mimir)
        prometheus.remote_write "mimir" {
          endpoint {
            // This points to the Mimir Gateway service
            url = "http://mimir-gateway.observability.svc.cluster.local/api/v1/push"

            // If your Mimir has multi-tenancy enabled (default in some charts), 
            // you MUST provide a Tenant ID header.
            headers = {
              "X-Scope-OrgID" = "CompanyA-Cluster1-Jakarta", 
            }
            
            // If you set up Basic Auth for Mimir, add this:
            /*
            basic_auth {
              username = "your-user"
              password = "your-password"
            }
            */
          }

          // Optional: Global labels added to EVERY metric
          external_labels = {
            "cluster" = "cloud-a-cluster-1-jakarta",
          }
        }